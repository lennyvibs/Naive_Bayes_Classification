{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b87ef03",
   "metadata": {},
   "source": [
    "# DISASTER TWEETS NB DATASET\n",
    "Using the above dataset to build a Naive Bayes Model to predict the nature of the tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862d5061",
   "metadata": {},
   "source": [
    "## BUSINESS OBJECTIVE\n",
    "* Maximize Accurate prediction\n",
    "* Minimize Fake news \n",
    "* Identify False Claims"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ec6d84",
   "metadata": {},
   "source": [
    "## CONSTRAINTS\n",
    "* Authenticating information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070c9b64",
   "metadata": {},
   "source": [
    "## DATA DICTIONARY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a47d442",
   "metadata": {},
   "source": [
    "| **slno** | **Name of Feature** | **Description**                                         | **Type**     | **Relevance** |\n",
    "|:--------:|:--------------------|:--------------------------------------------------------|:------------:|:-------------:|\n",
    "| 1        | id                  | Id of the tweet                                         | Count        | Irrelevant    |\n",
    "| 2        | keyword             | Keywords in the tweet                                   | Categorical  | Irrelevant    |\n",
    "| 3        | location            | Location from which the tweet was posted                | Categorical  | Irrelevant    |\n",
    "| 4        | text                | Text content of the tweet                               | Categorical  | Relevant      |\n",
    "| 5        | target              | 1 for disaster and 0 for no disaster                    | Binary       | Relevant      |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e5d637",
   "metadata": {},
   "source": [
    "Importing the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17e87c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from termcolor import colored\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB as MB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26adb47",
   "metadata": {},
   "source": [
    "Loading the dataset using the pandas library and confirming the dataset has been loaded properly using the 'head' function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fd16244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df0 = pd.read_csv(r\"D:\\360Digitmg\\ASSIGNMENTS\\Ass14\\Disaster_tweets_NB.csv\")\n",
    "df=df0.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b969727",
   "metadata": {},
   "source": [
    "### EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89606ccd",
   "metadata": {},
   "source": [
    "The below three lines give a general idea about the dataset like the shape, type and non null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46c129c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16c1f67c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           int64\n",
       "keyword     object\n",
       "location    object\n",
       "text        object\n",
       "target       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "414ae339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ee999b",
   "metadata": {},
   "source": [
    "The describe function gives the count, min, max, mean, standard deviation and quantile values of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12c467cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7613.000000</td>\n",
       "      <td>7613.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5441.934848</td>\n",
       "      <td>0.42966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3137.116090</td>\n",
       "      <td>0.49506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2734.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5408.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8146.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10873.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id      target\n",
       "count   7613.000000  7613.00000\n",
       "mean    5441.934848     0.42966\n",
       "std     3137.116090     0.49506\n",
       "min        1.000000     0.00000\n",
       "25%     2734.000000     0.00000\n",
       "50%     5408.000000     0.00000\n",
       "75%     8146.000000     1.00000\n",
       "max    10873.000000     1.00000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7717389",
   "metadata": {},
   "source": [
    "Checking the Number of Duplicates in the Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e5d1006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m Number of Duplicate values: \u001b[0m 0\n"
     ]
    }
   ],
   "source": [
    "duplicate_values=df.duplicated(subset=None,keep='first').sum()\n",
    "print(colored(' Number of Duplicate values: ','blue',attrs=['bold']),duplicate_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596b1b85",
   "metadata": {},
   "source": [
    "Checking the Number and Percentage of Missing Values in the Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72d872c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mNumber of Missing Values\n",
      "\n",
      "\u001b[0m location    2533\n",
      "keyword       61\n",
      "id             0\n",
      "text           0\n",
      "target         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing=df.isna().sum().sort_values(ascending=False)\n",
    "print(colored(\"Number of Missing Values\\n\\n\",'blue',attrs=['bold']),missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "422f0bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mNumber of Unique Values:\n",
      "\n",
      "\u001b[0m id          7613\n",
      "keyword      221\n",
      "location    3341\n",
      "text        7503\n",
      "target         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(colored('Number of Unique Values:\\n\\n','blue',attrs=['bold']),df.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f557916",
   "metadata": {},
   "source": [
    "Dropping the below three columns as they are irrelevant for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2665a8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1\n",
       "1             Forest fire near La Ronge Sask. Canada       1\n",
       "2  All residents asked to 'shelter in place' are ...       1\n",
       "3  13,000 people receive #wildfires evacuation or...       1\n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(df[['id','keyword','location']],axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e96b7fd",
   "metadata": {},
   "source": [
    "Converting the text data into lower case text data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e456bdfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>our deeds are the reason of this #earthquake m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>forest fire near la ronge sask. canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>just got sent this photo from ruby #alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  our deeds are the reason of this #earthquake m...       1\n",
       "1             forest fire near la ronge sask. canada       1\n",
       "2  all residents asked to 'shelter in place' are ...       1\n",
       "3  13,000 people receive #wildfires evacuation or...       1\n",
       "4  just got sent this photo from ruby #alaska as ...       1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']=df['text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae3f40e",
   "metadata": {},
   "source": [
    "Removing all the extra characters keeping only the alphabet data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "687efd86",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenny\\AppData\\Local\\Temp\\ipykernel_33364\\62207158.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['text']=df['text'].str.replace('[^a-z\" \"]+','')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>people receive wildfires evacuation orders in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  our deeds are the reason of this earthquake ma...       1\n",
       "1              forest fire near la ronge sask canada       1\n",
       "2  all residents asked to shelter in place are be...       1\n",
       "3   people receive wildfires evacuation orders in...       1\n",
       "4  just got sent this photo from ruby alaska as s...       1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']=df['text'].str.replace('[^a-z\" \"]+','')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df3ebb6",
   "metadata": {},
   "source": [
    "Loading custom stop words as a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbab0d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = []\n",
    "# Load the custom built Stopwords\n",
    "with open(r\"C:\\Users\\lenny\\Downloads\\stop_words_english.txt\",\"r\",encoding='utf-8') as sw:\n",
    "    stop_words = sw.read()\n",
    "\n",
    "stop_words = stop_words.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78b0ee1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['able',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abroad',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'across',\n",
       " 'actually',\n",
       " 'adj',\n",
       " 'after',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ago',\n",
       " 'ahead',\n",
       " \"ain't\",\n",
       " 'all',\n",
       " 'allow',\n",
       " 'allows',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alongside',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'amid',\n",
       " 'amidst',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'an',\n",
       " 'and',\n",
       " 'another',\n",
       " 'any',\n",
       " 'anybody',\n",
       " 'anyhow',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywhere',\n",
       " 'apart',\n",
       " 'appear',\n",
       " 'appreciate',\n",
       " 'appropriate',\n",
       " 'are',\n",
       " \"aren't\",\n",
       " 'around',\n",
       " 'as',\n",
       " \"a's\",\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'asking',\n",
       " 'associated',\n",
       " 'at',\n",
       " 'available',\n",
       " 'away',\n",
       " 'awfully',\n",
       " 'back',\n",
       " 'backward',\n",
       " 'backwards',\n",
       " 'be',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'been',\n",
       " 'before',\n",
       " 'beforehand',\n",
       " 'begin',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'believe',\n",
       " 'below',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'best',\n",
       " 'better',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'both',\n",
       " 'brief',\n",
       " 'but',\n",
       " 'by',\n",
       " 'came',\n",
       " 'can',\n",
       " 'cannot',\n",
       " 'cant',\n",
       " \"can't\",\n",
       " 'caption',\n",
       " 'cause',\n",
       " 'causes',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'changes',\n",
       " 'clearly',\n",
       " \"c'mon\",\n",
       " 'co',\n",
       " 'co.',\n",
       " 'com',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'concerning',\n",
       " 'consequently',\n",
       " 'consider',\n",
       " 'considering',\n",
       " 'contain',\n",
       " 'containing',\n",
       " 'contains',\n",
       " 'corresponding',\n",
       " 'could',\n",
       " \"couldn't\",\n",
       " 'course',\n",
       " \"c's\",\n",
       " 'currently',\n",
       " 'dare',\n",
       " \"daren't\",\n",
       " 'definitely',\n",
       " 'described',\n",
       " 'despite',\n",
       " 'did',\n",
       " \"didn't\",\n",
       " 'different',\n",
       " 'directly',\n",
       " 'do',\n",
       " 'does',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'done',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'downwards',\n",
       " 'during',\n",
       " 'each',\n",
       " 'edu',\n",
       " 'eg',\n",
       " 'eight',\n",
       " 'eighty',\n",
       " 'either',\n",
       " 'else',\n",
       " 'elsewhere',\n",
       " 'end',\n",
       " 'ending',\n",
       " 'enough',\n",
       " 'entirely',\n",
       " 'especially',\n",
       " 'et',\n",
       " 'etc',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'evermore',\n",
       " 'every',\n",
       " 'everybody',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everywhere',\n",
       " 'ex',\n",
       " 'exactly',\n",
       " 'example',\n",
       " 'except',\n",
       " 'fairly',\n",
       " 'far',\n",
       " 'farther',\n",
       " 'few',\n",
       " 'fewer',\n",
       " 'fifth',\n",
       " 'first',\n",
       " 'five',\n",
       " 'followed',\n",
       " 'following',\n",
       " 'follows',\n",
       " 'for',\n",
       " 'forever',\n",
       " 'former',\n",
       " 'formerly',\n",
       " 'forth',\n",
       " 'forward',\n",
       " 'found',\n",
       " 'four',\n",
       " 'from',\n",
       " 'further',\n",
       " 'furthermore',\n",
       " 'get',\n",
       " 'gets',\n",
       " 'getting',\n",
       " 'given',\n",
       " 'gives',\n",
       " 'go',\n",
       " 'goes',\n",
       " 'going',\n",
       " 'gone',\n",
       " 'got',\n",
       " 'gotten',\n",
       " 'greetings',\n",
       " 'had',\n",
       " \"hadn't\",\n",
       " 'half',\n",
       " 'happens',\n",
       " 'hardly',\n",
       " 'has',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'hello',\n",
       " 'help',\n",
       " 'hence',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hereafter',\n",
       " 'hereby',\n",
       " 'herein',\n",
       " \"here's\",\n",
       " 'hereupon',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'hi',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'hither',\n",
       " 'hopefully',\n",
       " 'how',\n",
       " 'howbeit',\n",
       " 'however',\n",
       " 'hundred',\n",
       " \"i'd\",\n",
       " 'ie',\n",
       " 'if',\n",
       " 'ignored',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'immediate',\n",
       " 'in',\n",
       " 'inasmuch',\n",
       " 'inc',\n",
       " 'inc.',\n",
       " 'indeed',\n",
       " 'indicate',\n",
       " 'indicated',\n",
       " 'indicates',\n",
       " 'inner',\n",
       " 'inside',\n",
       " 'insofar',\n",
       " 'instead',\n",
       " 'into',\n",
       " 'inward',\n",
       " 'is',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " 'its',\n",
       " \"it's\",\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'k',\n",
       " 'keep',\n",
       " 'keeps',\n",
       " 'kept',\n",
       " 'know',\n",
       " 'known',\n",
       " 'knows',\n",
       " 'last',\n",
       " 'lately',\n",
       " 'later',\n",
       " 'latter',\n",
       " 'latterly',\n",
       " 'least',\n",
       " 'less',\n",
       " 'lest',\n",
       " 'let',\n",
       " \"let's\",\n",
       " 'like',\n",
       " 'liked',\n",
       " 'likely',\n",
       " 'likewise',\n",
       " 'little',\n",
       " 'look',\n",
       " 'looking',\n",
       " 'looks',\n",
       " 'low',\n",
       " 'lower',\n",
       " 'ltd',\n",
       " 'made',\n",
       " 'mainly',\n",
       " 'make',\n",
       " 'makes',\n",
       " 'many',\n",
       " 'may',\n",
       " 'maybe',\n",
       " \"mayn't\",\n",
       " 'me',\n",
       " 'mean',\n",
       " 'meantime',\n",
       " 'meanwhile',\n",
       " 'merely',\n",
       " 'might',\n",
       " \"mightn't\",\n",
       " 'mine',\n",
       " 'minus',\n",
       " 'miss',\n",
       " 'more',\n",
       " 'moreover',\n",
       " 'most',\n",
       " 'mostly',\n",
       " 'mr',\n",
       " 'mrs',\n",
       " 'much',\n",
       " 'must',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'name',\n",
       " 'namely',\n",
       " 'nd',\n",
       " 'near',\n",
       " 'nearly',\n",
       " 'necessary',\n",
       " 'need',\n",
       " \"needn't\",\n",
       " 'needs',\n",
       " 'neither',\n",
       " 'never',\n",
       " 'neverf',\n",
       " 'neverless',\n",
       " 'nevertheless',\n",
       " 'new',\n",
       " 'next',\n",
       " 'nine',\n",
       " 'ninety',\n",
       " 'no',\n",
       " 'nobody',\n",
       " 'non',\n",
       " 'none',\n",
       " 'nonetheless',\n",
       " 'noone',\n",
       " 'no-one',\n",
       " 'nor',\n",
       " 'normally',\n",
       " 'not',\n",
       " 'nothing',\n",
       " 'notwithstanding',\n",
       " 'novel',\n",
       " 'now',\n",
       " 'nowhere',\n",
       " 'obviously',\n",
       " 'of',\n",
       " 'off',\n",
       " 'often',\n",
       " 'oh',\n",
       " 'ok',\n",
       " 'okay',\n",
       " 'old',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'ones',\n",
       " \"one's\",\n",
       " 'only',\n",
       " 'onto',\n",
       " 'opposite',\n",
       " 'or',\n",
       " 'other',\n",
       " 'others',\n",
       " 'otherwise',\n",
       " 'ought',\n",
       " \"oughtn't\",\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'outside',\n",
       " 'over',\n",
       " 'overall',\n",
       " 'own',\n",
       " 'particular',\n",
       " 'particularly',\n",
       " 'past',\n",
       " 'per',\n",
       " 'perhaps',\n",
       " 'placed',\n",
       " 'please',\n",
       " 'plus',\n",
       " 'possible',\n",
       " 'presumably',\n",
       " 'probably',\n",
       " 'provided',\n",
       " 'provides',\n",
       " 'que',\n",
       " 'quite',\n",
       " 'qv',\n",
       " 'rather',\n",
       " 'rd',\n",
       " 're',\n",
       " 'really',\n",
       " 'reasonably',\n",
       " 'recent',\n",
       " 'recently',\n",
       " 'regarding',\n",
       " 'regardless',\n",
       " 'regards',\n",
       " 'relatively',\n",
       " 'respectively',\n",
       " 'right',\n",
       " 'round',\n",
       " 'said',\n",
       " 'same',\n",
       " 'saw',\n",
       " 'say',\n",
       " 'saying',\n",
       " 'says',\n",
       " 'second',\n",
       " 'secondly',\n",
       " 'see',\n",
       " 'seeing',\n",
       " 'seem',\n",
       " 'seemed',\n",
       " 'seeming',\n",
       " 'seems',\n",
       " 'seen',\n",
       " 'self',\n",
       " 'selves',\n",
       " 'sensible',\n",
       " 'sent',\n",
       " 'serious',\n",
       " 'seriously',\n",
       " 'seven',\n",
       " 'several',\n",
       " 'shall',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"shouldn't\",\n",
       " 'since',\n",
       " 'six',\n",
       " 'so',\n",
       " 'some',\n",
       " 'somebody',\n",
       " 'someday',\n",
       " 'somehow',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'sometime',\n",
       " 'sometimes',\n",
       " 'somewhat',\n",
       " 'somewhere',\n",
       " 'soon',\n",
       " 'sorry',\n",
       " 'specified',\n",
       " 'specify',\n",
       " 'specifying',\n",
       " 'still',\n",
       " 'sub',\n",
       " 'such',\n",
       " 'sup',\n",
       " 'sure',\n",
       " 'take',\n",
       " 'taken',\n",
       " 'taking',\n",
       " 'tell',\n",
       " 'tends',\n",
       " 'th',\n",
       " 'than',\n",
       " 'thank',\n",
       " 'thanks',\n",
       " 'thanx',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'thats',\n",
       " \"that's\",\n",
       " \"that've\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'thence',\n",
       " 'there',\n",
       " 'thereafter',\n",
       " 'thereby',\n",
       " \"there'd\",\n",
       " 'therefore',\n",
       " 'therein',\n",
       " \"there'll\",\n",
       " \"there're\",\n",
       " 'theres',\n",
       " \"there's\",\n",
       " 'thereupon',\n",
       " \"there've\",\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'thing',\n",
       " 'things',\n",
       " 'think',\n",
       " 'third',\n",
       " 'thirty',\n",
       " 'this',\n",
       " 'thorough',\n",
       " 'thoroughly',\n",
       " 'those',\n",
       " 'though',\n",
       " 'three',\n",
       " 'through',\n",
       " 'throughout',\n",
       " 'thru',\n",
       " 'thus',\n",
       " 'till',\n",
       " 'to',\n",
       " 'together',\n",
       " 'too',\n",
       " 'took',\n",
       " 'toward',\n",
       " 'towards',\n",
       " 'tried',\n",
       " 'tries',\n",
       " 'truly',\n",
       " 'try',\n",
       " 'trying',\n",
       " \"t's\",\n",
       " 'twice',\n",
       " 'two',\n",
       " 'un',\n",
       " 'under',\n",
       " 'underneath',\n",
       " 'undoing',\n",
       " 'unfortunately',\n",
       " 'unless',\n",
       " 'unlike',\n",
       " 'unlikely',\n",
       " 'until',\n",
       " 'unto',\n",
       " 'up',\n",
       " 'upon',\n",
       " 'upwards',\n",
       " 'us',\n",
       " 'use',\n",
       " 'used',\n",
       " 'useful',\n",
       " 'uses',\n",
       " 'using',\n",
       " 'usually',\n",
       " 'v',\n",
       " 'value',\n",
       " 'various',\n",
       " 'versus',\n",
       " 'very',\n",
       " 'via',\n",
       " 'viz',\n",
       " 'vs',\n",
       " 'want',\n",
       " 'wants',\n",
       " 'was',\n",
       " \"wasn't\",\n",
       " 'way',\n",
       " 'we',\n",
       " \"we'd\",\n",
       " 'welcome',\n",
       " 'well',\n",
       " \"we'll\",\n",
       " 'went',\n",
       " 'were',\n",
       " \"we're\",\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'whatever',\n",
       " \"what'll\",\n",
       " \"what's\",\n",
       " \"what've\",\n",
       " 'when',\n",
       " 'whence',\n",
       " 'whenever',\n",
       " 'where',\n",
       " 'whereafter',\n",
       " 'whereas',\n",
       " 'whereby',\n",
       " 'wherein',\n",
       " \"where's\",\n",
       " 'whereupon',\n",
       " 'wherever',\n",
       " 'whether',\n",
       " 'which',\n",
       " 'whichever',\n",
       " 'while',\n",
       " 'whilst',\n",
       " 'whither',\n",
       " 'who',\n",
       " \"who'd\",\n",
       " 'whoever',\n",
       " 'whole',\n",
       " \"who'll\",\n",
       " 'whom',\n",
       " 'whomever',\n",
       " \"who's\",\n",
       " 'whose',\n",
       " 'why',\n",
       " 'will',\n",
       " 'willing',\n",
       " 'wish',\n",
       " 'with',\n",
       " 'within',\n",
       " 'without',\n",
       " 'wonder',\n",
       " \"won't\",\n",
       " 'would',\n",
       " \"wouldn't\",\n",
       " 'yes',\n",
       " 'yet',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\",\n",
       " 'zero',\n",
       " 'a',\n",
       " \"how's\",\n",
       " 'i',\n",
       " \"when's\",\n",
       " \"why's\",\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'j',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'uucp',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " 'I',\n",
       " 'www',\n",
       " 'amount',\n",
       " 'bill',\n",
       " 'bottom',\n",
       " 'call',\n",
       " 'computer',\n",
       " 'con',\n",
       " 'couldnt',\n",
       " 'cry',\n",
       " 'de',\n",
       " 'describe',\n",
       " 'detail',\n",
       " 'due',\n",
       " 'eleven',\n",
       " 'empty',\n",
       " 'fifteen',\n",
       " 'fifty',\n",
       " 'fill',\n",
       " 'find',\n",
       " 'fire',\n",
       " 'forty',\n",
       " 'front',\n",
       " 'full',\n",
       " 'give',\n",
       " 'hasnt',\n",
       " 'herse',\n",
       " 'himse',\n",
       " 'interest',\n",
       " 'itse”',\n",
       " 'mill',\n",
       " 'move',\n",
       " 'myse”',\n",
       " 'part',\n",
       " 'put',\n",
       " 'show',\n",
       " 'side',\n",
       " 'sincere',\n",
       " 'sixty',\n",
       " 'system',\n",
       " 'ten',\n",
       " 'thick',\n",
       " 'thin',\n",
       " 'top',\n",
       " 'twelve',\n",
       " 'twenty',\n",
       " 'abst',\n",
       " 'accordance',\n",
       " 'act',\n",
       " 'added',\n",
       " 'adopted',\n",
       " 'affected',\n",
       " 'affecting',\n",
       " 'affects',\n",
       " 'ah',\n",
       " 'announce',\n",
       " 'anymore',\n",
       " 'apparently',\n",
       " 'approximately',\n",
       " 'aren',\n",
       " 'arent',\n",
       " 'arise',\n",
       " 'auth',\n",
       " 'beginning',\n",
       " 'beginnings',\n",
       " 'begins',\n",
       " 'biol',\n",
       " 'briefly',\n",
       " 'ca',\n",
       " 'date',\n",
       " 'ed',\n",
       " 'effect',\n",
       " 'et-al',\n",
       " 'ff',\n",
       " 'fix',\n",
       " 'gave',\n",
       " 'giving',\n",
       " 'heres',\n",
       " 'hes',\n",
       " 'hid',\n",
       " 'home',\n",
       " 'id',\n",
       " 'im',\n",
       " 'immediately',\n",
       " 'importance',\n",
       " 'important',\n",
       " 'index',\n",
       " 'information',\n",
       " 'invention',\n",
       " 'itd',\n",
       " 'keys',\n",
       " 'kg',\n",
       " 'km',\n",
       " 'largely',\n",
       " 'lets',\n",
       " 'line',\n",
       " \"'ll\",\n",
       " 'means',\n",
       " 'mg',\n",
       " 'million',\n",
       " 'ml',\n",
       " 'mug',\n",
       " 'na',\n",
       " 'nay',\n",
       " 'necessarily',\n",
       " 'nos',\n",
       " 'noted',\n",
       " 'obtain',\n",
       " 'obtained',\n",
       " 'omitted',\n",
       " 'ord',\n",
       " 'owing',\n",
       " 'page',\n",
       " 'pages',\n",
       " 'poorly',\n",
       " 'possibly',\n",
       " 'potentially',\n",
       " 'pp',\n",
       " 'predominantly',\n",
       " 'present',\n",
       " 'previously',\n",
       " 'primarily',\n",
       " 'promptly',\n",
       " 'proud',\n",
       " 'quickly',\n",
       " 'ran',\n",
       " 'readily',\n",
       " 'ref',\n",
       " 'refs',\n",
       " 'related',\n",
       " 'research',\n",
       " 'resulted',\n",
       " 'resulting',\n",
       " 'results',\n",
       " 'run',\n",
       " 'sec',\n",
       " 'section',\n",
       " 'shed',\n",
       " 'shes',\n",
       " 'showed',\n",
       " 'shown',\n",
       " 'showns',\n",
       " 'shows',\n",
       " 'significant',\n",
       " 'significantly',\n",
       " 'similar',\n",
       " 'similarly',\n",
       " 'slightly',\n",
       " 'somethan',\n",
       " 'specifically',\n",
       " 'state',\n",
       " 'states',\n",
       " 'stop',\n",
       " 'strongly',\n",
       " 'substantially',\n",
       " 'successfully',\n",
       " 'sufficiently',\n",
       " 'suggest',\n",
       " 'thered',\n",
       " 'thereof',\n",
       " 'therere',\n",
       " 'thereto',\n",
       " 'theyd',\n",
       " 'theyre',\n",
       " 'thou',\n",
       " 'thoughh',\n",
       " 'thousand',\n",
       " 'throug',\n",
       " 'til',\n",
       " 'tip',\n",
       " 'ts',\n",
       " 'ups',\n",
       " 'usefully',\n",
       " 'usefulness',\n",
       " \"'ve\",\n",
       " 'vol',\n",
       " 'vols',\n",
       " 'wed',\n",
       " 'whats',\n",
       " 'wheres',\n",
       " 'whim',\n",
       " 'whod',\n",
       " 'whos',\n",
       " 'widely',\n",
       " 'words',\n",
       " 'world',\n",
       " 'youd',\n",
       " 'youre']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c485a8",
   "metadata": {},
   "source": [
    "Removing all the stop words in the text data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cafe9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deeds reason earthquake allah forgive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>forest la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>residents asked shelter place notified officer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>people receive wildfires evacuation orders cal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>photo ruby alaska smoke wildfires pours school</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0              deeds reason earthquake allah forgive       1\n",
       "1                        forest la ronge sask canada       1\n",
       "2  residents asked shelter place notified officer...       1\n",
       "3  people receive wildfires evacuation orders cal...       1\n",
       "4     photo ruby alaska smoke wildfires pours school       1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']=df['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop_words ))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207d8b87",
   "metadata": {},
   "source": [
    "### MODEL BUILDING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e72d850",
   "metadata": {},
   "source": [
    "Splitting the dataframe into test and train dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7022773d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test= train_test_split(df,test_size=0.2,random_state=1000,stratify=df.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037852a7",
   "metadata": {},
   "source": [
    "Creating a custom function to tokenize the text in each rows of the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85fcf241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_words(i):\n",
    "    return [word for word in i.split(\" \")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2020ae",
   "metadata": {},
   "source": [
    "Converting texts in to word count matrix format i.e Bag of words using CountVectorizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8ea7907",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bow=CountVectorizer(analyzer=split_into_words).fit(df.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf79ecf",
   "metadata": {},
   "source": [
    "BOW for entire Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f25579b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matrix=df_bow.transform(df.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ab65dc",
   "metadata": {},
   "source": [
    "BOW for training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b5dbcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_matrix=df_bow.transform(df_train.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7dc11f",
   "metadata": {},
   "source": [
    "BOW for test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13ae7e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_matrix=df_bow.transform(df_test.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a400938b",
   "metadata": {},
   "source": [
    "Learning Term Weighting and normalizing on entire dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4324c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer=TfidfTransformer().fit(df_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0307cb13",
   "metadata": {},
   "source": [
    "Preparing TFIDF for train dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "304bda8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6090, 20877)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_tfidf=tfidf_transformer.transform(df_train_matrix)\n",
    "df_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158b050a",
   "metadata": {},
   "source": [
    "Preparing TFIDF for test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f3870a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1523, 20877)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_tfidf=tfidf_transformer.transform(df_test_matrix)\n",
    "df_test_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e32dfb8",
   "metadata": {},
   "source": [
    "Preparing a naive bayes model on training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7fa41b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_mb=MB()\n",
    "classifier_mb.fit(df_train_tfidf, df_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd82e45",
   "metadata": {},
   "source": [
    "Evaluation on test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "137f9c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred=classifier_mb.predict(df_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac22ab3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Actuals</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predictions</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>770</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99</td>\n",
       "      <td>445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Actuals        0    1\n",
       "Predictions          \n",
       "0            770  209\n",
       "1             99  445"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(test_pred, df_test.target,rownames = ['Predictions'], colnames= ['Actuals'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e56c1f",
   "metadata": {},
   "source": [
    "Test data accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "498dfcd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7977675640183848"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_pred, df_test.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4abe36b",
   "metadata": {},
   "source": [
    "Train Data accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d21b9423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9203612479474549"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred=classifier_mb.predict(df_train_tfidf)\n",
    "accuracy_score(train_pred,df_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "083c5fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Actuals</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predictions</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3394</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79</td>\n",
       "      <td>2211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Actuals         0     1\n",
       "Predictions            \n",
       "0            3394   406\n",
       "1              79  2211"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(train_pred,df_train.target,rownames = ['Predictions'], colnames= ['Actuals'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56fb9b6",
   "metadata": {},
   "source": [
    "### HYPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7d15fe",
   "metadata": {},
   "source": [
    "Apply laplace smoothing to carryout hyperparameter tuning and evaluating both train and test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c19d33d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_mb_lap=MB(alpha=1)\n",
    "classifier_mb_lap.fit(df_train_tfidf, df_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35b97c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_lap=classifier_mb_lap.predict(df_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e3414cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7977675640183848"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_pred_lap, df_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77240cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Actuals</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predictions</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>770</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99</td>\n",
       "      <td>445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Actuals        0    1\n",
       "Predictions          \n",
       "0            770  209\n",
       "1             99  445"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(test_pred_lap, df_test.target,rownames = ['Predictions'], colnames= ['Actuals'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "829a2153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9203612479474549"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred_lap=classifier_mb_lap.predict(df_train_tfidf)\n",
    "accuracy_score(train_pred_lap,df_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8280e3ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Actuals</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predictions</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3394</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79</td>\n",
       "      <td>2211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Actuals         0     1\n",
       "Predictions            \n",
       "0            3394   406\n",
       "1              79  2211"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(train_pred_lap, df_train.target,rownames = ['Predictions'], colnames= ['Actuals'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318a80cf",
   "metadata": {},
   "source": [
    "### CONCLUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f06ec45",
   "metadata": {},
   "source": [
    "This model is not good for prediction as it is overfitting , so the best option is to try another model.This analysis would help to identify the emergency tweets so that help would be given at the earliest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dea3d14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
